{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ ~ Download and Pickle Weather Data~ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cross_correlation_ratio',\n",
       " 'differential_phase',\n",
       " 'differential_reflectivity',\n",
       " 'spectrum_width',\n",
       " 'clutter_filter_power_removed',\n",
       " 'reflectivity',\n",
       " 'velocity']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download NEXRAD Data \n",
    "#Store output on local machine after first run, takes a long time\n",
    "import pyart\n",
    "import fsspec\n",
    "#from metpy.plots import UtSCOUNTIES\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle\n",
    "\n",
    "\n",
    "fs = fsspec.filesystem(\"s3\", anon=True)\n",
    "files = sorted(fs.glob(\"s3://noaa-nexrad-level2/2022/06/02/KHGX/KHGX20220602_18*\"))\n",
    "radar = pyart.io.read_nexrad_archive(f's3://{files[3]}')\n",
    "list(radar.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send to a pickled file once appropriate data is deterimined\n",
    "with open('weatherdat.pickle', 'wb') as handle:\n",
    "    pickle.dump(radar, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-25T16:50:43.493610Z",
     "iopub.status.busy": "2022-07-25T16:50:43.493164Z",
     "iopub.status.idle": "2022-07-25T16:50:49.135542Z",
     "shell.execute_reply": "2022-07-25T16:50:49.134706Z",
     "shell.execute_reply.started": "2022-07-25T16:50:43.493515Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ ~ Load Weather Data From Pickle ~ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:50:49.139237Z",
     "iopub.status.busy": "2022-07-25T16:50:49.138879Z",
     "iopub.status.idle": "2022-07-25T16:50:50.498860Z",
     "shell.execute_reply": "2022-07-25T16:50:50.497804Z",
     "shell.execute_reply.started": "2022-07-25T16:50:49.139204Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"weatherdat.pickle\", \"rb\") as f:\n",
    "    l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:50:50.500650Z",
     "iopub.status.busy": "2022-07-25T16:50:50.500288Z",
     "iopub.status.idle": "2022-07-25T16:50:50.543236Z",
     "shell.execute_reply": "2022-07-25T16:50:50.542509Z",
     "shell.execute_reply.started": "2022-07-25T16:50:50.500614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cross_correlation_ratio', 'differential_phase', 'differential_reflectivity', 'spectrum_width', 'clutter_filter_power_removed', 'reflectivity', 'velocity']\n"
     ]
    }
   ],
   "source": [
    "print(list(l.fields))\n",
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:50:50.545061Z",
     "iopub.status.busy": "2022-07-25T16:50:50.544703Z",
     "iopub.status.idle": "2022-07-25T16:50:50.575236Z",
     "shell.execute_reply": "2022-07-25T16:50:50.574380Z",
     "shell.execute_reply.started": "2022-07-25T16:50:50.545015Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mmtrand.pyx:4435\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:55:10.264498Z",
     "iopub.status.busy": "2022-07-25T16:55:10.264170Z",
     "iopub.status.idle": "2022-07-25T16:55:10.270300Z",
     "shell.execute_reply": "2022-07-25T16:55:10.269517Z",
     "shell.execute_reply.started": "2022-07-25T16:55:10.264448Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_conv(img):\n",
    "    size = 6\n",
    "    stride = 5\n",
    "    ret = np.ones((3,3))\n",
    "    stx=0\n",
    "    for i in range(3):\n",
    "        sty = 0\n",
    "        for j in range(3):\n",
    "            ret[i][j] = np.mean(img[stx:stx+size, sty:sty+size])\n",
    "            sty += stride\n",
    "        stx += stride\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:55:10.885774Z",
     "iopub.status.busy": "2022-07-25T16:55:10.884954Z",
     "iopub.status.idle": "2022-07-25T16:55:12.619276Z",
     "shell.execute_reply": "2022-07-25T16:55:12.618324Z",
     "shell.execute_reply.started": "2022-07-25T16:55:10.885722Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      2\u001b[0m high_img \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(l))):\n\u001b[1;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m l[i]\n\u001b[1;32m      5\u001b[0m     img[np\u001b[38;5;241m.\u001b[39misnan(img)]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(img[\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(img)])    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "SIZE = 16\n",
    "high_img = []\n",
    "for i in tqdm(range(len(l))):\n",
    "    img = l[i]\n",
    "    img[np.isnan(img)]=np.mean(img[~np.isnan(img)])    \n",
    "    #resizing image\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    high_img.append(img)\n",
    "temp_img = []\n",
    "low_img = []\n",
    "for i in tqdm(range(len(l))):\n",
    "    img = l[i]\n",
    "    img[np.isnan(img)]=np.mean(img[~np.isnan(img)])    \n",
    "    #resizing image\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    temp = mean_conv(img)\n",
    "    temp_img.append(temp)\n",
    "    img = cv2.resize(temp, (SIZE, SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    low_img.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:55:14.094586Z",
     "iopub.status.busy": "2022-07-25T16:55:14.094267Z",
     "iopub.status.idle": "2022-07-25T16:55:15.016559Z",
     "shell.execute_reply": "2022-07-25T16:55:15.015678Z",
     "shell.execute_reply.started": "2022-07-25T16:55:14.094555Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh Resolution Imge\u001b[39m\u001b[38;5;124m'\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mhigh_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAJTCAYAAAD34IZ+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc3UlEQVR4nO3de7RkZXmg8eeFtjUqikI7MYCCpo02xBnkiDIYxVEjMBl61vIydMIYE0aMGYgXRsF4KQqijppEo8ELrlFyEQGdxHQiLmZU0OiA0gpeAElaQGm80CpgIpFLfOePbx+7KOr02d3UOdX99vNbq9c5VbWr6qtddZ7atS/VkZlIkmrYbdYDkCRNj1GXpEKMuiQVYtQlqRCjLkmFGHVJKsSo7+BiGBnDuHgKt3NxDMP9V4EYxtndfN1/ie/ntO5+jljK+5FGrZj1AHYF8zHNQcZWprkeeCRwQA7y+uUZ2faJYZwGDMbOvh3YBHwKeOOO/himIYbxQuADwG/lIM+e7Wj6GXnuhjnI02Y7Gi0Fo77jexxw26wHsYBPAxd3v+8F/AfgRcBzYxhPykH+46wGtoP4U+Bc4FuzHoh2HUZ9B5eD/Pqsx7AVF48u7cUwdgP+Fjga+H3gt2Y0rh1CDvL7wPdnPQ7tWoz6Dq5bdfPpHOQRY+c/HHgj8B+BPYBrgLcB3wQuYoGP1zGMFcCraMF9BHATcA7wuhzkHfdmrDnIn8YwzqZF/YkT7vv+wEuB/wKsBhL4KvCOHOSHxqYN4AXAi7tp9wA2A1cB789Bnjc2/SG0N5JfAR4MfBf4GHBGDvI7i429W++9tfl2ffcY9+9OXww8rbv4AzGMD4xMfkAO8vqRVR1Pz0FePHZ7zwBeCRwKPID2vP0V8KYc5K1j087f131Youeue95+E3gU7TX1u93v3wXO6saVMYzndeM+EPgxcD7wyhzkv0y4zd8ATqZ92vwn4ELglG7MT5u0OjKG8Wzaa+RQ2nO+iTZf3pCDvOXePMZdhVHfCcUwHgZcQlsH/xng/wE/D7wL+D+LXP0cWvg+DvyIFuBXAQ9jukvWd46NeU/a+vaDgS8B76dtqH82cE4M48Ac5GtHrvIG4NXAdbRw3Ao8nPZm8TzgvJHb/jXgfwMBfIQWyEOAlwBrYxhPyUFeN8XHBnA2cAuwFvgb4IqRy27Z2hVjGC8G3k2L4odpcT6CFrz/FMM4fIGALcdz94fdWP6W9lo6hvZcrIxh/BD4n8BHgb8HngX8d2B32rwefYyvAt4M3Az8Ge35exbwue73e4hhDIDTgB8Cf0ebL48H/gdwdAzjsBzkj6b0OMsy6suoW3JbyJ7bcFNvogX9LTnIU0Zu/+3AFxa57qOBA3OQP+yu8xrgy8ALYhivzkF+dxvGcTcxjN2B47uTnx27+O20oJ+Sg3zLyHXuR4vE78cwPpKDvKK76MXAjcBBOci7bVOIYew98vsDadFYARyRg/z7kctOoUXovcCvbu/jmiQHeXYMA1rUP9p3Q2kM45HAO4B/Bg4dXb0Ww3gXLY5vAU6YcPUle+5GHAI8Pgd5Y3cfpwEbaUvntwGH5CCv7i67L3A58NsxjEEO8qbu/EfR3gi+DzwhB3lDd/6ptDemY8fvNIbxdFrQLwGOHn1TG9kgPQRePoXHWJq7NC6vwVb+PbjPDcQwVgLraEs7fzB6WQ7yy8CfL3ITp8xHobvOj4EP0l4Lc70exRZHdLvtnRbDeAfwNdqS91XAGSNj3gs4DtgwGvTu/n9CW0IN4NfHbv9O4F/H77RbVz1vLfBQ4LzRoHf+CLgeeFYM4xHb+NiWynHASuBPJ2wveQ1tNcV/7YI5bprP3ULOmA96dx+3AOuB+wPvng96d9nttE9MK2mrWOb9Ou1N9p3zQe+mT+BUJjynwO91P180/imle8O8AviN7XxMuxSX1JdRz10aF/NLwM/RAvlPEy7/LPDftnL9DRPOm//De0iP+x/1NLasV553BW2JefQj9hNpH9FzgU8r9+l+jobhg8BJwFUxjPNpe9pcMr6+GXhC9/NT4zeag7wrhvEZYH/ap4QdYS+UrY335hjG5cBTgcfSlsJHTfO5W8ik+/h29/OLEy6bfwPYd+S8g7uf45/WyEF+M4ZxA+05GXUY7U38ed16+3ErgVUxjL1ykD9YYOzCqO+M5pfov7fA5QudD/xsyWvcXd3P3bdxLMMc5GndXi/70NZ9/h5wfgzjqBzkT7vp9up+PpEJG1BHPHDk95cD19LWFZ/a/bsrhnEBcHIOcmM33fz8WGhj6Pz5e/Z7SEtuu8c75eduIZPWd9/V47L7jJzX5zW6/9h5e9F6NH78w7gHAkZ9K4z6zmd+Q9G/WeDyhc5fMl28bwBeGsP4BeC5wIm0dcewJQZvy0G+oudt/ittPfzbuw3DT6Gti30ecGC3YfX2kdv++QVu6uFjY1jI/BvQQn8Te7LIBtCeRsd75YTL+453Rzb6Gp30GCe9Rm8FdstBPnTJRrWLcJ36zufrwL8Aj49h7DHh8qcs83jGnUw7uvT1MYwHded9gRbNX9meG8xB3pSD/Ksc5PNpqy0eDRzUXXx59/OI8et1u2/O3+eXFrmbm7uf+024nV9k8jaP+XXD27KUvLXx7gn8O+AnwNXjl+9E5h/jPV6L3Ybie8xj4FLgITGMA5dyYLsCo76T6fZHPo8WmdFdAIlh/Fvavt0zk4P8FvA+2sfpk7vzbqKtI5+LYbyu20vmbmIYj45hHND9ft8YxuETprkPbaMobDnK9qO0XeDWxTCePHaVlwEHAJ/oxrU1X6ctYa7tPhnM3+fPseUTx7j51QDbshH2L2nrjk/q3ixGnQE8CPjL7lPIzuoc2mqZk2IYPwt4d+zBm5j8Jvi27uf7uk97dxPDeMCE51cTuPpl53Qq7ZD8V8UwnkTbT/3hwPOBC4D/zJbVCbPwRtqujS+PYbyz21vlRNpBRKfT9u74LG3d6i/QNpA+kbZXz3W0DcGfjWFspG2c+yZwP9p+zo8D1s/vhZGD/OcYxm/T9vf+dAzjw7QNoofQdmP8Lm33yK3KQd4Zw/gT4HXA5TGMv6b9fTyLtqHw2xOudgntzeVl3R4+87sUvnPCBt35+7k+hvEy4EzgS91G4M20Dc6H0d5cTpl03Z1FDvIbMYzX014HX45hnMeW/dQfStsA/Pix63yy2+XxTcA/dttOrqOtQ38kbf58Fjhy2R7ITsol9Z1QDvJ7wL+n7b54IG2j4sG0owA/2E02s4M0uiM43007IvDV3Xk/ov1hnkTbf/k5wCuAp9N243s58H+7m/gxLWwbaY/zpbTd5H5E24/7bntH5CD/Bjic9ob2bNoG28cB76HtV31tz6EPuvH+hLaf+NG0g5qezdjBVN393tw9jquAF9KWtM9gkT1RcpDv6m7zUrbMh4cBbwUOG91tcWeVg3wT7VPjN2kbu4+nrVI6nPZmeY/XZw7yzbQ9fz7WTfcy2nO9D+2o1teOX0f3FJl+G2slMYw30A6XPzIHeeGsxyON6razfA+4Igd52KzHU5FL6jupBdY7/jJtl8If0vbrlmYihrGq2wYyet4K2gFh9wP+eiYD2wUsuk49It4P/BpwU2YeNOHyAP6E9lH1NuCFmbnYnga69zZ065y/RltdsZr2RUy7AS/ujtSUZuU5wOkxjE/Qdnd9KG3VymNoB6i9c3ZDq63PhtKzad8LvdDh50fRgrIaeBJtXeqTpjE4bdV7aRtE19HWXd9C+xa8Pxz/RkBpBj5P27D5VLYcfHYd7Tth3jzpWx01Hb3WqUfE/sDfLbCk/l7g4sz21akRcQ1wRObiX3cqSZquaezSuA9bvn8C2vcf78OEw6Aj4gS6b597wAMecMhjH/vYKdy9JNXyxS9+8fuZuWp7rrus+6ln5lm0XZOYm5vLDRsmfXeQJO3aIuKb23vdaez9ciN3P+x3X7Z8c5skaRlNI+rrgRdE82TgVtenS9Js9Nml8UO0Lx/aOyI20Y66uw9AZr6HdhTf0bSj/25jF//PhiVplhaNemauW+TypP0/hZKkGfOIUkkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVEivqEfEkRFxTURsjIhTJ1z+iIi4KCIuj4ivRMTR0x+qJGkxi0Y9InYHzgSOAtYA6yJizdhkrwXOz8yDgWOBd017oJKkxfVZUj8U2JiZ12bmHcC5wNqxaRJ4UPf7g4FvT2+IkqS++kR9H+CGkdObuvNGnQYcFxGbgAuAkybdUEScEBEbImLD5s2bt2O4kqStmdaG0nXA2Zm5L3A08BcRcY/bzsyzMnMuM+dWrVo1pbuWJM3rE/Ubgf1GTu/bnTfqeOB8gMy8BLgfsPc0BihJ6q9P1C8DVkfEARGxkrYhdP3YNN8CngEQEY+jRd31K5K0zBaNembeBZwIXAhcTdvL5cqIOD0ijukmOxl4UUR8GfgQ8MLMzKUatCRpshV9JsrMC2gbQEfPe/3I71cBh093aJKkbeURpZJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqZBeUY+IIyPimojYGBGnLjDN8yPiqoi4MiLOme4wJUl9rFhsgojYHTgTeBawCbgsItZn5lUj06wGXg0cnpk3R8TDlmrAkqSF9VlSPxTYmJnXZuYdwLnA2rFpXgScmZk3A2TmTdMdpiSpjz5R3we4YeT0pu68UY8BHhMRn4uISyPiyEk3FBEnRMSGiNiwefPm7RuxJGlB09pQugJYDRwBrAPeFxF7jk+UmWdl5lxmzq1atWpKdy1Jmtcn6jcC+42c3rc7b9QmYH1m3pmZ1wH/QIu8JGkZ9Yn6ZcDqiDggIlYCxwLrx6b5KG0pnYjYm7Y65trpDVOS1MeiUc/Mu4ATgQuBq4HzM/PKiDg9Io7pJrsQ+EFEXAVcBLwyM3+wVIOWJE0WmTmTO56bm8sNGzbM5L4laUcWEV/MzLntua5HlEpSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUSK+oR8SREXFNRGyMiFO3Mt1zIiIjYm56Q5Qk9bVo1CNid+BM4ChgDbAuItZMmG4P4KXA56c9SElSP32W1A8FNmbmtZl5B3AusHbCdGcAbwZ+MsXxSZK2QZ+o7wPcMHJ6U3fez0TEE4D9MvNjW7uhiDghIjZExIbNmzdv82AlSVt3rzeURsRuwB8DJy82bWaelZlzmTm3atWqe3vXkqQxfaJ+I7DfyOl9u/Pm7QEcBFwcEdcDTwbWu7FUkpZfn6hfBqyOiAMiYiVwLLB+/sLMvDUz987M/TNzf+BS4JjM3LAkI5YkLWjRqGfmXcCJwIXA1cD5mXllRJweEccs9QAlSf2t6DNRZl4AXDB23usXmPaIez8sSdL28IhSSSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUSK+oR8SREXFNRGyMiFMnXP6KiLgqIr4SEZ+MiEdOf6iSpMUsGvWI2B04EzgKWAOsi4g1Y5NdDsxl5uOBjwBvmfZAJUmL67OkfiiwMTOvzcw7gHOBtaMTZOZFmXlbd/JSYN/pDlOS1EefqO8D3DByelN33kKOBz4+6YKIOCEiNkTEhs2bN/cfpSSpl6luKI2I44A54K2TLs/MszJzLjPnVq1aNc27liQBK3pMcyOw38jpfbvz7iYingm8BnhaZt4+neFJkrZFnyX1y4DVEXFARKwEjgXWj04QEQcD7wWOycybpj9MSVIfi0Y9M+8CTgQuBK4Gzs/MKyPi9Ig4ppvsrcADgQ9HxBURsX6Bm5MkLaE+q1/IzAuAC8bOe/3I78+c8rgkSdvBI0olqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhRl2SCjHqklSIUZekQoy6JBVi1CWpEKMuSYUYdUkqxKhLUiFGXZIKMeqSVIhRl6RCjLokFWLUJakQoy5JhRh1SSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqRCjLkmFGHVJKsSoS1IhvaIeEUdGxDURsTEiTp1w+X0j4rzu8s9HxP5TH6kkaVGLRj0idgfOBI4C1gDrImLN2GTHAzdn5i8CbwPePO2BSpIW12dJ/VBgY2Zem5l3AOcCa8emWQv8Wff7R4BnRERMb5iSpD5W9JhmH+CGkdObgCctNE1m3hURtwJ7Ad8fnSgiTgBO6E7eHhFf255BF7M3Y/NpF+Q8aJwPjfMBfml7r9gn6lOTmWcBZwFExIbMnFvO+98ROR+cB/OcD43zoc2D7b1un9UvNwL7jZzetztv4jQRsQJ4MPCD7R2UJGn79In6ZcDqiDggIlYCxwLrx6ZZD/xm9/tzgU9lZk5vmJKkPhZd/dKtIz8RuBDYHXh/Zl4ZEacDGzJzPfC/gL+IiI3AD2nhX8xZ92LclTgfnAfznA+N8+FezINwgVqS6vCIUkkqxKhLUiFLHnW/YqDXPHhFRFwVEV+JiE9GxCNnMc6ltth8GJnuORGREVFyt7Y+8yEint+9Jq6MiHOWe4xLrcffxCMi4qKIuLz7uzh6FuNcShHx/oi4aaHjdaJ5RzePvhIRT+h1w5m5ZP9oG1a/ATwKWAl8GVgzNs3vAu/pfj8WOG8px7Tc/3rOg6cD9+9+f0m1edB3PnTT7QF8BrgUmJv1uGf0elgNXA48pDv9sFmPewbz4CzgJd3va4DrZz3uJZgPTwWeAHxtgcuPBj4OBPBk4PN9bnepl9T9ioEe8yAzL8rM27qTl9KOBaimz2sB4Azadwf9ZDkHt4z6zIcXAWdm5s0AmXnTMo9xqfWZBwk8qPv9wcC3l3F8yyIzP0PbW3Aha4E/z+ZSYM+IePhit7vUUZ/0FQP7LDRNZt4FzH/FQBV95sGo42nvztUsOh+6j5f7ZebHlnNgy6zP6+ExwGMi4nMRcWlEHLlso1sefebBacBxEbEJuAA4aXmGtkPZ1nYAy/w1Adq6iDgOmAOeNuuxLLeI2A34Y+CFMx7KjmAFbRXMEbRPbZ+JiF/OzFtmOahltg44OzP/KCIOox0Hc1Bm/nTWA9vRLfWSul8x0G8eEBHPBF4DHJOZty/T2JbTYvNhD+Ag4OKIuJ62DnF9wY2lfV4Pm4D1mXlnZl4H/AMt8lX0mQfHA+cDZOYlwP1oX/S1K+nVjnFLHXW/YqDHPIiIg4H30oJebf3pvK3Oh8y8NTP3zsz9M3N/2raFYzJzu7/YaAfV52/io7SldCJib9rqmGuXcYxLrc88+BbwDICIeBwt6puXdZSztx54QbcXzJOBWzPzO4teaxm28B5NW9L4BvCa7rzTaX+w0J6sDwMbgS8Aj5r1VukZzINPAN8Druj+rZ/1mGcxH8amvZiCe7/0fD0EbVXUVcBXgWNnPeYZzIM1wOdoe8ZcAfzqrMe8BPPgQ8B3gDtpn86OB34H+J2R18GZ3Tz6at+/B78mQJIK8YhSSSrEqEtSIUZdkgox6pJUiFGXpEKMuiQVYtQlqZD/D0FI9Po/EjAZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    a = np.random.randint(0,3600)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "    plt.imshow(high_img[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(low_img[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('temp Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(temp_img[a])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and Reshaping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:55:21.893378Z",
     "iopub.status.busy": "2022-07-25T16:55:21.893059Z",
     "iopub.status.idle": "2022-07-25T16:55:21.921451Z",
     "shell.execute_reply": "2022-07-25T16:55:21.919465Z",
     "shell.execute_reply.started": "2022-07-25T16:55:21.893349Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'low_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_high_image \u001b[38;5;241m=\u001b[39m high_img[:\u001b[38;5;241m2304\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m train_low_image \u001b[38;5;241m=\u001b[39m \u001b[43mlow_img\u001b[49m[:\u001b[38;5;241m2304\u001b[39m]\n\u001b[1;32m      3\u001b[0m train_high_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(train_high_image,(\u001b[38;5;28mlen\u001b[39m(train_high_image),SIZE,SIZE,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m train_low_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(train_low_image,(\u001b[38;5;28mlen\u001b[39m(train_low_image),SIZE,SIZE,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'low_img' is not defined"
     ]
    }
   ],
   "source": [
    "train_high_image = high_img[:2304]\n",
    "train_low_image = low_img[:2304]\n",
    "train_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,1))\n",
    "train_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,1))\n",
    "\n",
    "validation_high_image = high_img[2304:2880]\n",
    "validation_low_image = low_img[2304:2880]\n",
    "validation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,1))\n",
    "validation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,1))\n",
    "\n",
    "\n",
    "test_high_image = high_img[2880:]\n",
    "test_low_image = low_img[2880:]\n",
    "test_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,1))\n",
    "test_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,1))\n",
    "\n",
    "print(\"Shape of training images:\",train_high_image.shape)\n",
    "print(\"Shape of test images:\",test_high_image.shape)\n",
    "print(\"Shape of validation images:\",validation_high_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSD Conversion Into TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSD Training\n",
    "(from https://github.com/tjvandal/deepsd/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import ConfigParser\n",
    "\n",
    "base_srcnn = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'srcnn-tensorflow')\n",
    "sys.path.append(base_srcnn)\n",
    "from srcnn import srcnn\n",
    "from tfreader import inputs_climate\n",
    "\n",
    "\n",
    "flags = tf.flags\n",
    "flags.DEFINE_string('config_file', 'config.ini', 'Configuration file with [SRCNN] section.')\n",
    "flags.DEFINE_string('checkpoint_file', None, 'Any checkpoint with the same architecture as'\\\n",
    "                    'configured.')\n",
    "flags.DEFINE_string('model_number', '1', 'Experiment-? in config file/')\n",
    "\n",
    "# parse flags\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "\n",
    "\n",
    "\n",
    "## READ CONFIGURATION FILE\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.read(FLAGS.config_file)\n",
    "\n",
    "LAYER_SIZES = [int(k) for k in config.get('SRCNN', 'layer_sizes').split(\",\")]\n",
    "KERNEL_SIZES = [int(k) for k in config.get('SRCNN', 'kernel_sizes').split(\",\")]\n",
    "OUTPUT_DEPTH = LAYER_SIZES[-1]\n",
    "AUX_DEPTH = int(config.get('SRCNN', 'aux_depth'))\n",
    "LEARNING_RATE = float(config.get('SRCNN', 'learning_rate'))\n",
    "TRAINING_ITERS = int(config.get('SRCNN', 'training_iters'))\n",
    "BATCH_SIZE = int(config.get('SRCNN', 'batch_size'))\n",
    "TRAINING_INPUT_SIZE = int(config.get('SRCNN', 'training_input_size'))\n",
    "INPUT_DEPTH = int(config.get('SRCNN', 'training_input_depth'))\n",
    "SAVE_STEP = int(config.get('SRCNN', 'save_step'))\n",
    "TEST_STEP = int(config.get('SRCNN', 'test_step'))\n",
    "KEEP_PROB = 1. - float(config.get('SRCNN', 'dropout_prob'))\n",
    "\n",
    "# where to save and get data\n",
    "DATA_DIR = config.get('Model-%s' % FLAGS.model_number, 'data_dir')\n",
    "MODEL_NAME = config.get('Model-%s' % FLAGS.model_number, 'model_name')\n",
    "timestamp = str(int(time.time()))\n",
    "curr_time = dt.datetime.now()\n",
    "\n",
    "SAVE_DIR = os.path.join(config.get('SRCNN', 'scratch'), \"srcnn_%s_%s_%s\" % ( MODEL_NAME,\n",
    "                    '-'.join([str(s) for s in LAYER_SIZES]),\n",
    "                    '-'.join([str(s) for s in KERNEL_SIZES])))\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.mkdir(SAVE_DIR)\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default(), tf.device(\"/cpu:0\"):\n",
    "        global_step = tf.get_variable('global_step', [],\n",
    "                    initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        errors = []\n",
    "\n",
    "        # lets get data to iterate through\n",
    "        lr_size = int(TRAINING_INPUT_SIZE / 2)\n",
    "        train_images, train_labels = inputs_climate(BATCH_SIZE, TRAINING_ITERS,\n",
    "                        DATA_DIR, lr_shape=[lr_size, lr_size], lr_d=INPUT_DEPTH,\n",
    "                        aux_d=AUX_DEPTH, is_training=True,\n",
    "                        hr_shape=[TRAINING_INPUT_SIZE, TRAINING_INPUT_SIZE], hr_d=OUTPUT_DEPTH)\n",
    "        test_images, test_labels, test_times = inputs_climate(BATCH_SIZE, TRAINING_ITERS,\n",
    "                        DATA_DIR, is_training=False, lr_d=INPUT_DEPTH, aux_d=1,\n",
    "                        hr_d=OUTPUT_DEPTH)\n",
    "\n",
    "        # crop training labels\n",
    "        border_size = (sum(KERNEL_SIZES) - len(KERNEL_SIZES))/2\n",
    "        train_labels_cropped = train_labels[:,border_size:-border_size,border_size:-border_size,:]\n",
    "\n",
    "        # set placeholders\n",
    "        is_training = tf.placeholder_with_default(True, (), name='is_training')\n",
    "\n",
    "        x = tf.cond(is_training, lambda: train_images, lambda: test_images)\n",
    "        y = tf.cond(is_training, lambda: train_labels_cropped, lambda: test_labels)\n",
    "\n",
    "        x = tf.identity(x, name='x')\n",
    "        y = tf.identity(y, name='y')\n",
    "\n",
    "        # Use SRCNN\n",
    "        model = srcnn.SRCNN(x, y, LAYER_SIZES, KERNEL_SIZES, input_depth=INPUT_DEPTH,\n",
    "                            learning_rate=LEARNING_RATE, upscale_factor=2,\n",
    "                           is_training=is_training, gpu=True)\n",
    "        prediction = tf.identity(model.prediction, name='prediction')\n",
    "\n",
    "        # initialize graph and start session\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                log_device_placement=False))\n",
    "        sess.run(init)\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        # look for checkpoint\n",
    "        if FLAGS.checkpoint_file is not None:\n",
    "            try:\n",
    "                checkpoint = tf.train.latest_checkpoint(FLAGS.checkpoint_file)\n",
    "                saver.restore(sess, checkpoint)\n",
    "                print(\"Checkpoint\", checkpoint)\n",
    "            except tf.errors.InternalError as err:\n",
    "                print(\"Warning: Could not find checkpoint\", err)\n",
    "                pass\n",
    "\n",
    "        # start coordinator for data\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        # summary data\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(SAVE_DIR + '/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(SAVE_DIR + '/test', sess.graph)\n",
    "\n",
    "        def feed_dict(train=True):\n",
    "            return {is_training: train}\n",
    "\n",
    "        #curr_step = int(sess.run(model.global_step))\n",
    "        curr_step = 0\n",
    "        for step in range(curr_step, TRAINING_ITERS+1):\n",
    "            start_time = time.time()\n",
    "            _, train_loss, train_rmse = sess.run([model.opt, model.loss, model.rmse],\n",
    "                                                 feed_dict=feed_dict(True))\n",
    "            duration = time.time() - start_time\n",
    "            if step  % TEST_STEP == 0:\n",
    "                test_summary = sess.run(summary_op, feed_dict=feed_dict(True))\n",
    "                train_writer.add_summary(test_summary, step)\n",
    "\n",
    "                d = feed_dict(train=True)\n",
    "                out = sess.run([model.loss, model.rmse, summary_op, model.x_norm], feed_dict=d)\n",
    "                test_writer.add_summary(out[2], step)\n",
    "                print(\"Step: %d, Examples/sec: %0.5f, Training Loss: %2.3f,\" \\\n",
    "                        \" Train RMSE: %2.3f, Test RMSE: %2.4f\" % \\\n",
    "                        (step, BATCH_SIZE/duration, train_loss, train_rmse, out[1]))\n",
    "\n",
    "            if step % SAVE_STEP == 0:\n",
    "                save_path = saver.save(sess, os.path.join(SAVE_DIR, \"srcnn.ckpt\"))\n",
    "\n",
    "        save_path = saver.save(sess, os.path.join(SAVE_DIR, \"srcnn.ckpt\"))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:55:23.453515Z",
     "iopub.status.busy": "2022-07-25T16:55:23.453185Z",
     "iopub.status.idle": "2022-07-25T16:55:26.321078Z",
     "shell.execute_reply": "2022-07-25T16:55:26.320335Z",
     "shell.execute_reply.started": "2022-07-25T16:55:23.453460Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "def down(filters , kernel_size, apply_batch_normalization = True):\n",
    "    downsample = tf.keras.models.Sequential()\n",
    "    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n",
    "    if apply_batch_normalization:\n",
    "        downsample.add(layers.BatchNormalization())\n",
    "    downsample.add(keras.layers.LeakyReLU())\n",
    "    return downsample\n",
    "\n",
    "\n",
    "def up(filters, kernel_size, dropout = False):\n",
    "    upsample = tf.keras.models.Sequential()\n",
    "    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n",
    "    if dropout:\n",
    "        upsample.dropout(0.2)\n",
    "    upsample.add(keras.layers.LeakyReLU())\n",
    "    return upsample\n",
    "\n",
    "def model():\n",
    "    inputs = layers.Input(shape= [SIZE,SIZE,1])\n",
    "    d1 = down(128,(3,3),False)(inputs)\n",
    "    d2 = down(128,(3,3),False)(d1)\n",
    "    d3 = down(256,(3,3),True)(d2)\n",
    "    d4 = down(512,(3,3),True)(d3)\n",
    "    \n",
    "    #upsampling\n",
    "    u2 = up(256,(3,3),False)(d4)\n",
    "    u2 = layers.concatenate([u2,d3])\n",
    "    u3 = up(128,(3,3),False)(u2)\n",
    "    u3 = layers.concatenate([u3,d2])\n",
    "    u4 = up(128,(3,3),False)(u3)\n",
    "    u4 = layers.concatenate([u4,d1])\n",
    "    u5 = up(3,(3,3),False)(u4)\n",
    "    u5 = layers.concatenate([u5,inputs])\n",
    "    output = layers.Conv2D(1,(2,2),strides = 1, padding = 'same')(u5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:58:20.045842Z",
     "iopub.status.busy": "2022-07-25T16:58:20.045435Z",
     "iopub.status.idle": "2022-07-25T16:58:20.063367Z",
     "shell.execute_reply": "2022-07-25T16:58:20.062678Z",
     "shell.execute_reply.started": "2022-07-25T16:58:20.045808Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:58:21.305815Z",
     "iopub.status.busy": "2022-07-25T16:58:21.305501Z",
     "iopub.status.idle": "2022-07-25T16:58:58.207113Z",
     "shell.execute_reply": "2022-07-25T16:58:58.206417Z",
     "shell.execute_reply.started": "2022-07-25T16:58:21.305785Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_low_image, train_high_image, epochs = 40, batch_size = 16,\n",
    "          validation_data = (validation_low_image,validation_high_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T16:56:13.656901Z",
     "iopub.status.busy": "2022-07-25T16:56:13.656587Z",
     "iopub.status.idle": "2022-07-25T16:56:18.908257Z",
     "shell.execute_reply": "2022-07-25T16:56:18.907440Z",
     "shell.execute_reply.started": "2022-07-25T16:56:13.656872Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_images(high,low,predicted):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('High Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(high)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Low Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(low)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n",
    "    plt.imshow(predicted)\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "for i in range(100,110):\n",
    "    \n",
    "    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,1)),0.0,1.0).reshape(SIZE, SIZE,1)\n",
    "    plot_images(test_high_image[i],test_low_image[i],predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T15:15:29.150306Z",
     "iopub.status.busy": "2022-07-25T15:15:29.149756Z",
     "iopub.status.idle": "2022-07-25T15:15:29.281635Z",
     "shell.execute_reply": "2022-07-25T15:15:29.280856Z",
     "shell.execute_reply.started": "2022-07-25T15:15:29.150268Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
